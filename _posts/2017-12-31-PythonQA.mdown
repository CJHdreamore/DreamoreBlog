---
layout: post
title: 数据分析师问答汇总
img: data_analysis
date: 2017-12-31
categories: work
tags: [Q&A]
author: 陈小耗
---




#----------------------------------------------
#这是我在成为python数据分析师的路上的问题汇总
#以及我个人的理解与回答（prepare)
#-----------------------------------------------


#1.列举几个常用的python库以及其作用
#   数据处理和分析：Numpy 和 Pandas,Scipy
#   机器学习的top1: sklearn
#   可视化我常用：matplotlib
#-----------------------------------
# 1.1 Numpy和Scipy，Pandas的区别？
# Numpy矩阵运算，重在数学处理，这也是为什么它叫Numpy，number嘛
# Scipy则是在基于Numpy上更加接近科学处理，比如它有信号处理的滤波器等模块
# Pandas的核心在于提供了一种类似于表的数据结构：DataFrame,可以方便地做一些统计分析
# 总结：Numpy是N维数组容器；Scipy是科学函数计算库；Pandas是表格容器
# 让我们先把库import进来吧！
import numpy as np
import pandas as pd
#-------------------------------------
# 1.2 Numpy的n维数组的神奇之处？
# 根据Numpy的reference: Different ndarrays can share the same data,so that changes made in one
# ndarray may be visible in another.
# 这句话是说，如果你将一个ndarray赋给了另一个变量，那么当你通过该变量名改变ndarray时，原来那个ndarray也会变。
# 归根结底是因为，不同的变量名共享了同一个内存空间中的值
#-------------------------------------
# 1.3 如何创建一个n维数组？且对它的前n项进行排序
# 以创建一个(row,column)的矩阵为例
matrix = np.array([5,1,2])
# print (matrix)
#np.argsort(array,axis)返回的是排序好的index
sorted_matrix = matrix[matrix[:].argsort()]
# print (sorted_matrix)
#---------------------------------------
# 1.4 如何创建包含不同数据类型的dataframe?
# 先用pd.series创建列，再把这些列组合在一起形成表格dataframe
col_1 = pd.Series(['1.0','2.0','3.0'],dtype=float)
col_2 = pd.Series(['cat','pig','dog'],dtype=str)
df = pd.DataFrame({'rating':col_1,'animals':col_2})
# print (df)
# 1.5 如何取dataframe中的一列或一行？
one_col = df.animals
one_row = df.loc[[0]]
# 1.6 Pandas中使用的标准数据缺失标志是什么？
# NaN
# 1.7 为什么numpy中的数列比python原有的list有优势？造成这个优势的本质是因为什么？
# 先自己回答：我能感受到的是，numpy.array可以直接做向量运算，比如说数乘，点乘
# 而list却要通过for循环遍历去做。
x = np.array([1,2,3])
y = np.array([3,4,9])
z = np.multiply(x,y)
k = np.dot(x,y)
list1 = [1,2,3]
list2 = [3,4,9]
#不能做 result = list1 * list2
#两个numpy.array是可以直接用*，进行了操作符的重载吗？
#而python自带的乘法操作，是针对两个数值变量进行的，就像报错里面说的：
# can't multiply sequence by type 'list'
# print (x * y)
# 根据网上诸位回答的整理而成：numpy.array和list的区别？
# ①索引的区别：一个嵌套的list
a = [[1,2,3],[4,5,6],[7,8,9]]
#print (a[0,1])  会报错，list不支持tuple的索引
b = np.array([list1,list2])
print (b[0,1]) #numpy.ndarray是支持tuple的索引方式的
#因此，总结一：array比list的索引方式更加多样
# ② numpy.array的黑科技就在于它很快很快！
# list中的元素可以使任何对象，所以python的list中保存的是对象的指针-值这样的对，因此仅对数值
# 计算来说，这种结构是非常耗费内存和cpu计算时间的。
# python其实自己也有一个array模块（module),就是考虑到了这一点，所以它只保存了数值,但却不支持多维，也没有各种函数运算。
# numpy.array就是解决了以上两个问题！
# numpy给了我们两个法宝： ndarray（n维的array object), ufunc(全局的函数 object).
# 前者是单一数据类型的多维数组，后者是能够对这些数组进行处理的函数,比如我们的求均值、方差，etc
# 总结二：array比起list占用的存储空间，在数值计算时占用的cpu都更小，所以它更加高效。并且它自带的函数处理也会使得
# 数值计算非常方便。

# 1.8 我发现当在python源代码中敲入了太多中文注释，会非常明显地降低代码的运行速度？

按理说是不会影响的。但是为什么我在pycharm中debuging的时候明显感觉到速度慢了。

# 1.9 检验numpy数组为空，dataframe为空的方法
numpy.size：为空返回0
df.empty：返回True or False

# 2.0 dataframe类型的数据生成
pd.DataFrame(data,index=[],column=[],dtype=)
pd.DataFrame({'key':pd.Series,'key2':pd.Series2})

# 2.1 python里的method和function的区别
python里的method是实例化后的类中的函数，它是要和对象联系起来的，也就是说，method和一个类中的self息息相关。
而function则更宏大，未实例化的类的函数，它更加具有的是数学上的概念，并没有赋予一个实例的具体的self.x参数值。

再从英文定义上来体会：
funtion: a series of statements which returns some value to
         a caller.It can also be passed zero or more arguments which may be used in the exe of the body

method : a function which is defined inside a class body.
         If called as an attribute of an instance of that class.(这个类的一个实例的属性)The method will get
         the instance object as its first argument(which is usually called self)

#2.2 在python中定义类时，加不加object意味着什么？

醍醐灌顶，class Myclass(object)，就相当于是继承了object这个对象呀。
因为继承了object，就多了很多高级的可操作对象。比如__class__,__getattribute__等等。
如果只是靠自己在类中定义，那么最初只会有__doc__,__module__,这个类的命名空间中可操作的就太少了。

但是在python3中已经默认加了，所以只有在用python2.7的时候要
记住自己加object的继承呀！

#2.3 你如何理解python是一种面向对象的语言？
面向对象的语言体系中大约有两种关系：
一是父子的继承,这种关系存在于class之间。比如说某个子类（subclass)是另一个类（superclass)的继承。在我们自行定义类的时候，其实都是以object这个superlcass为父类的。
二是：一个对象（实例）是另一个对象（class)的具体实现。
      这句话说明，python中的对象是一个很泛的概念，它可以指
      class,也可以指一个instance。
      一个instance必然是某个class的具体实现。

python正是这样的结构。我们说在python中定义一个变量，比如说：a = 2
其实是在干什么呢？ 我们实例化了一个类！a = int(2)
int就是这个class！a是它的一个instance！
又一个醍醐灌顶：如果说x是A的实例，那么其实等价于说A是x的类型。a是int的实例，也就是说int是a的类型。

#2.4 怎么理解python中的对象（object)?
python的起源？type是metaclass，也就是说，后续的一切都是type的实例化。但是type作为一个metaclass有没有base呢？
那就是起源之二：object超类。
type和object是一个鸡生蛋蛋生鸡的问题。
因为object是type的一个实例，然而type的base又是object类。
从object生成的观点来看，它是一个实例，由type实例化得到。
从type生成的观点来看，object是一个超类，type通过继承它来定义。

总结：1）python中有两种对象：
      类型对象:可以被实例化和继承，比如int就是一个内置的类型对象。
      非类型对象：不可以被实例化和继承，比如a = 2，a就是个非类型对象。
      2）class 'type'和class 'object'是python中的两个类型对象。
      3）每个对象都有类型，用__class__查看
      4) 每个类型对象都有超类（object)除外，用__bases__查看
      5）通过实例化，既可能产生类型对象：type对象的实例化产生了int;也可能产生非类型对象，int对象的实例化产生了a。
      6）实例化是通过操作符（）实现的。

#2.4 迭代器（iterator)与iteratble
一个实例对象是iterable的，那么它的method中必须有一个__iter__(),这个method返回一个iterator，用于for循环，或者其他接受iterator的类的实例化过程中.

#2.5 python的函数式编程：mapreduce
函数式编程是从“范畴论”起源的，简单的理解就是：（集合+函数），集合中的各种成员是通过函数变形来transform的。

如果把范畴想象成一个容器，那么里面包含两样东西：
值（value) 和 值的变形关系（函数）

函数式编程有两个最基本的运算：合成和柯里化
合成是指把多个函数merge起来，比如z = g(f(x))
柯里化是指把一个多参的函数转化为一个单一参数输入的函数

函子（Functor)是一种范畴，它也包含了值和变形关系，特殊的是它的变形关系可以依次作用于每一个值，从而将当前的范畴变为另一个范畴。如果说函数是一个范畴之中的转换，那么函子就是可以实现从范畴到另一范畴转换的container.

如果一个容器具有map方法，就可以将容器里的每一个值，映射到另一个容器。那么这个容器就是一个函子。

#2.6 python中有哪些比较典型的函子？
lambda x,y；x+y 冒号前面是输入的自变量，冒号后是描述函数的具体操作

map函数map(func,iterible)
reduce函数，记得要从functools中import（python3)
reduce(func,iterable),一次对iterable中的两个数做func操作

filter(lambda x:x>0,iterible)
etc

#----------------------------------------------------
#数学统计部分

#3.0 什么是logistic regression? 和对数回归（log-linear regression)有什么区别？

虽然经常翻译为逻辑回归，但是我更喜欢把它理解为对率回归，也就是logit regression.
我认为logistic regression比较神奇的一点事，虽然叫回归，但它本来的用途是
用一个线性模型来做二分类。我们希望预测的值属于{0,1},一个阶跃函数。
但是这个函数不连续，不能通过求导来求最优解。所以我们希望用替代函数来尽量逼近这个阶跃函数，但是又需要它光滑而连续。Sigmoid曲线，也就是S曲线是直觉上的一种很好的近似。于是数学家们为这个样子的曲线搞出了一堆函数，也就是Sigmoid函数。logistic function就是其中的一个，为什么机器学习里面钟爱它，从我个人的感触是，我觉得它能够得到比较好的物理解释。

logistic regression是说，线性函数并不是用来直接得到预测y，而是得到对率，即判断y/(1-y)，因为线性回归得到的y本质上是一个连续的value，我们是通过一个threshold来判定，y为正例还是负例，所以y可以解释为:将样本判为正例的概率。于是y/(1-y)就是将样本判为正例的相对概率，就是英文中的logit。
于是logistic regression的概念就明确了，用线性模型得到对率，或者说是那个著名的逻辑回归公式。


线性回归模型意味着，我们认为x和y的变化尺度是一致的，但实际情况往往是，dy，也就是y的变化率并不是线性的。比如房价，往往是一个指数变化的趋势。
#-----------------
#3.1 P值的意义，和alpha值的联系？
这是在假设检验中常用到的一个参数。
用通俗的话来解释显著性分析中的p值：在机器学习中一个常见的场景是，我们在训练集上训练出了一个模型，然后我们在测试集上得出了预测结果，这个预测结果和真值的差异，就是我们的error，或者用loss损失来度量。
显著性分析不是说，这个差异有多大，比如4和40的差异很大。
显著性是说，差异真不真实。
比如我们度量了predict和ground-truth之间的均方误差。那么这个差异显著吗，是说这个差异体现出来的随机性有多大。p值就是差异随机性的度量，p越小，说明这个差异的随机性越小，也就是说predict和ground-truth之间的差异是很显著的，很小的概率是因为样本的随机性带来的差异。因此，我们认为算得的均方误差是可以用来度量这个模型的性能的。比如传统的p<0.05.
如果p>阈值，那么我们就要拒绝用均方误差来度量模型的损失了，因为这个差异不显著，也就是说，这种度量可能带有很大的随机性。
#-------------------
#3.2 在python中随机生成三组二维数据（中心分开），再用Kmeans的方法进行聚类。
这是在QuantUrban的面试中的问题，当时我卡在了：生成的三个二维数组要怎么结合为一个数据集。
彼时我的思路是，如果三个随机二维数组都是10*10的，那么最后结合成为的数据集应该是30*10（sample,feature).但当时因为我直接生成的三个数组都是np.array结构，于是我就不知道应该怎么合并了。
现在我的解决方法是： 1.使用一个numpy函数（numpy.hstack())
                     将生成的三个cluster以元祖的形式输入该函数，这个函数将会把这三个10*10的矩阵按列拼接起来，也就是成为一个10*30的矩阵。因此最后还要通过转置来形成（sample,feature)的数据格式。

                     2.用list来做。这种方法有些许笨拙了。因为一开始我的随机数组是由numpy生成的，所以在生成了numpy二维数组之后，我首先需要把三个cluster数据都转化为list。再使用list.extend（input_list)来将list合并。注意，list.append(input_value)会将输入的任何数据都当做一个元素来加入原始列表，而extend才是把新输入的列表中的数据合并到原始列表中。extend之后，我需要再次把该list转化为array再利用reshape函数把array转化为我想要的（sample,feature)的格式。
                     可见，这种方式可以说是很笨拙了。
                     还是记住用np.hstack((array1,array2))这个方式吧！不过要注意它是增加列的方式拼接的。
     

