---
layout: post
title: 聚类的性能度量
img: cluster.jpg
date: 2017-12-31
categories: learning
tags: [sklearn]
author: 陈小耗
---
本文是对sklearn聚类度量的翻译和理解：
--------------------

 “Adjustment for chance in clustering performance evaluation”

 避免随机性的聚类性能度量标准


前言：簇的数目，样本的数目在不同的聚类性能度量（clustering performance evaluation metrics）上有什么影响呢？

***
 1.Adjusted Rand index （外部指标）

 这种度量方式要求已知真实的标记labels_true，还有通过聚类得到的标记labels_pred。ARI做的就是度量真实标记和预测标记之间的相似度(similarity).

- 优势:
       1.对一个随机分布（均匀分布）的标记集，它的ARI分数将接近于0。不管样本数和簇的数为多少。这条特性，让ARI可以成为consensus index（一致性指标）

       2.ARI是有界的[-1,1]，越负代表聚类结果越不好。

       3.ARI度量没有对簇的结构做任何假设。k-means这种假设isotropic簇可以用，spectral clustering这种为找到簇的folded样式的模型也可以用ARI来评价。也就是说它可以用来作不同聚类算法之间的比较。

- 劣势： 需要真实的label，这其实很悖论了。不过如可以利用外部的专家信息作为真实label，ARI还是可以用的。


理解ARI: ARI的数学公式中，分子代表了什么意思？

如果我们从样本集中随机挑选一对（xi,xj），若它们在簇中属于同一个簇，在真实的类中也属于同一个类。那么直觉上，我们就认为这样的聚类效果比较好，所以我们希望在所有样本对中，满足这样情况的pair越多越好。另一方面，如果我们挑选出来的pair它们在簇中不属于同一簇，那么我们也希望它们真实的也是不同类，所以分子上是两部分数目之和。

**ARI是通过计算样本集上的样本对在簇上和真实类别上的划分是否一致来衡量的。**

**为什么要用样本对的概念呢？**

难道不可以针对一个样本，如果它在簇中属于某个簇，在类中也属于这个类，或者它不属于某个簇，相应地在类中也不属于某个类。这样不行吗？

如果是这样的话，**那么这个性能度量就会和簇的数目有关了**。

而我们知道ARI是无关簇和样本的数目的。它之所以做到了这一点，就是由于它利用了一个样本对的观点。是通过样本对的表现，而不是单个样本的表现，来避免了对样本数和簇数的依赖。

***
2.Mutual Information based scores 基于互信息的分数

同样是一个外部指标,需要知道真实的标记。于是我想知道，它和ARI有什么区别呢？

看起来，用互信息来度量真实标记和预测标记之间的相似度，与ARI有一种殊途同归的feel，除了它计算出来的值是在[0,1]，因为它是以熵来作为度量的。
从demo-2中也可以看出，ARI和AMI在三种init方法上虽然计算的值不同，但都显示出模型的性能是：PCA-based > random >k-means++

***
3.一致性、完全性及V-值

这三个仍然是外部指标，我感觉有点像监督学习性能度量中的查准率，查全率和F-值。

- 一致性是指：每一个簇都只包含同一类样本的度量

- 完全性是指：属于一个类的所有的样本都被聚为同一簇

看，这不是和查准率和查全率非常近似吗？

同样的，V-值就是对一致性和完全性的一个综合考量，采用的也是调和平均。


- 优势：可解释性，一致性、完全性都具有很好的可解释性，比起ARI和AMI似乎更加的直观。当然它也有ARI,AMI的bounded和没有对簇的结构进行任何假设的好处。
- 劣势：
> not normalized with regards to random labeling.

在这种性能度量下，如果标记是完全随机生成的（也就意味着聚类完全没有效果），按理说，我们希望得到的分数是0（最差），然而一致性、完全性和V-measure并不会如我们所愿。

换句话说，这种性能度量和样本数，簇的数目以及真实的类别的数目都是有关的。

> For smaller sample sizes or larger number of clusters,it is safer to use an ARI or AMI

**对于小样本，多类别的情况，使用ARI或者AMI这种避免随机性的指标作为聚类结果的性能度量更好。**

***
4.FMI

- TP（True Positive，真正）：在真实标记和预测标记中都属于同一簇的样本对的个数。

- FP（假正）：在真正的标记中属于同一簇，但在预测标记中属于不同簇。

FMI是样本对的查准率（precision）和查全率(recall)的几何平均数。

- 优势：和一致性和完备性不同了，FMI是adjusted的，也就是和n_clusters和n_samples无关的性能度量方法。同时它也是bounded和no assumption on structure的。

- 劣势：同样的需要知道真实标记。

**这么看来FMI和ARI,AMI的适用场景都差不多啊。**

***
5.Silhouette Coefficient（终于有一个内部指标了！）

SC值越高，说明这个聚类的模型越好。

SC中的参数定义： 

- a.对于一个样本而言，和它属于同一个簇（这里cluster和class不做区分，因为我们不知道真实的标记，故理所当然地认为预测得到的cluster标记就是样本真实的标记）的其他所有样本点的距离的平均值。

- b.对于一个样本而言，离它所属的簇最近的那个簇中的所有样本点与它距离的平均值。

SC = （b-a）/max(a,b),这样就计算出来了一个样本的SC值。

对样本集上所有样本的sc取平均值作为最后的sc。

**为什么说SC越大，聚类模型越好呢？**

b-a说明：b从某种意义上是簇间距离的一种衡量，a则是一个簇的凝聚度的度量。b-a越大，聚类越好是很容易理解的。

而分母，应该是一个用来归一化的因子。

- 优势：不正确的聚类结果，那么sc趋近-1；正确的聚类，sc趋近1；sc在0附近说明，聚类有重叠。（overlapping clusters）

- 劣势：SC在通常意义上会在凸集的聚类上分数高于其他样式的数据，比如高密度的数据集（DBSCAN），说明SC作为一种评价方式，是有其偏好的。

sklearn有专门的一篇文章来写"如何利用SC值来选择最优的聚类数目"

***
6.Calinski-Harabaz Index(sklearn提供的最后一种度量方式）

这也是一种内部指标。同样的CH值越高，说明聚类模型越好。

这是通过：within-cluster dispersion matrix和 between group dispersion matrix来度量的。

- 优势：
       1.分数的高低直接和簇的定义挂钩。簇的定义不就是簇内越凝聚，不同簇间越分开吗。

       2.这个指标的计算很快。（这一点如何体现的...）

- 劣势：同样的，它和SC值一样也是对凸的数据集会打分高。
 
 










